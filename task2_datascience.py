# -*- coding: utf-8 -*-
"""Task2 DataScience.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t-gjuEqYh54NlPAIHu_Fr7TBG73RS7oN

# **EMPLOYEE TURNOVER PREDICTION TASK**

# **Important Libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import confusion_matrix ,f1_score
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import chi2
from sklearn.feature_selection import SelectKBest
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import LabelEncoder
from sklearn.compose import make_column_selector as selector
from sklearn.pipeline import Pipeline

df= pd.read_csv('/content/WA_Fn-UseC_-HR-Employee-Attrition (1).csv')
df

df.shape

df.describe(include='all')

df.isnull().any()

df.isin(['?']).sum()

df.duplicated().sum()

duplicates = df.duplicated()
duplicates_in_columns = df[duplicates].notna().any()
duplicates_in_columns

df.dtypes

df.nunique()

# Create a box plot using Plotly Express
import plotly.express as px
fig = px.box(
    data_frame=df,
    x="Gender",
    y="HourlyRate",
    color="Gender",
    facet_col="Attrition",
    title="Hourly Rate Distribution by Gender and Attrition",
    labels={"Gender": "Gender", "HourlyRate": "Hourly Rate"},
    color_discrete_sequence=px.colors.qualitative.Set1
)

# Update facet labels
facet_col_labels = {
    "Yes": "Attrition: Yes",
    "No": "Attrition: No"
}

for i, label in enumerate(facet_col_labels.values()):
    fig.layout.annotations[i].text = label

# Update layout with font properties
fig.update_layout(
    legend_title="Gender",
    xaxis_title=None,
    yaxis_title="Hourly Rate",
    margin=dict(t=100),  # Adjust top margin to accommodate facet labels
    title_font=dict(size=25, family='Verdana'),
)

# Update font properties of annotations
for annotation in fig.layout.annotations:
    annotation.font = dict(size=20, family='Verdana')

# Show the plot
fig.show()

import plotly.express as px
dept_att = df.groupby(['Department','Attrition']).apply(lambda x: x['DailyRate'].count()).reset_index(name='Counts')
px.bar(dept_att, x='Department', y='Counts', color='Attrition', title='Breakdown of employees by department within an organizationüè¢üë•')

env_att = df.groupby(['EnvironmentSatisfaction','Attrition']).apply(lambda x: x['DailyRate'].count()).reset_index(name='Counts')
px.area(env_att, x='EnvironmentSatisfaction', y='Counts', color='Attrition', title='Employee headcount in an organization based on environment satisfaction levelsüíºüåü')

df['BusinessTravel'].unique()

df['Department'].unique()

df['EducationField'].unique()

df['JobRole'].unique()

df['MaritalStatus'].unique()

df['Over18'].unique()

df['OverTime'].unique()

df.shape

df.hist(bins=50,figsize=(20,20))
plt.show()

plt.figure(figsize=(8,8))
sns.boxplot(data=df,x='DailyRate',y='Attrition')

plt.figure(figsize=(16, 9))
sns.heatmap(df.corr(), annot=True)

cor = df.corr()
plt.figure(figsize=(20,15))
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)
plt.show()

corr_matrix = df.corr()
fig, ax = plt.subplots(figsize=(15, 10))
ax = sns.heatmap(corr_matrix,
 annot=True,
linewidths=0.5,
fmt=".2f",
cmap="YlGnBu");
bottom, top = ax.get_ylim()
ax.set_ylim(bottom + 0.5, top - 0.5)

# Calculate the correlation matrix
corr_matrix = df.corr()

# Print the correlation matrix
print(corr_matrix)

#SO WE WILL DROP : 2 COLUMNS StandardHours AND EmployeeCount FROM THE NUMERICAL DATA

df['Attrition'].value_counts().plot(kind='pie',autopct='%0.1f')
plt.title("Distribution of Attrition in dataset")

df.dtypes

# get numerical data
num_data =df.select_dtypes(include=['int64'])

num_data.columns

# get categorical data
cat_data = df.select_dtypes(include=['object'])

cat_data.columns

from sklearn.feature_selection import SelectKBest, chi2

df['Attrition'] = df['Attrition'].replace('Yes', '1')
df['Attrition'] = df['Attrition'].replace('No', '0')
df['Attrition']

df['Attrition'] = df['Attrition'].astype(int)

df.dtypes

drop_col = ['Over18', 'StandardHours','EmployeeCount']
df = df.drop(drop_col, axis=1)
df.head()

df=pd.get_dummies(df, columns=['BusinessTravel','Department','EducationField','JobRole','MaritalStatus','OverTime'])
le=LabelEncoder()
df['Gender']=le.fit_transform(df['Gender'])

df.dtypes

df.shape

df.columns

df.shape

# Define the feature matrix X and the target variable y
X = df.drop('Attrition', axis=1)  # Assuming 'Attrition' is the target variable
y = df['Attrition']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# **Decision Tree Model with Accuracy 77%**

"""

# Train a decision tree model
model = DecisionTreeClassifier()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Print test confusion matrix and classification report
print("Test Confusion Matrix")
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

# Calculate precision and recall
y_prob = model.predict_proba(X_test)
precision, recall, thresholds = precision_recall_curve(y_test, y_prob[:, 1])

# Plot the precision-recall curve
plt.plot(recall, precision, label='Logistic Model')
plt.legend()
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.show()

"""# **Logistic Model with Accuracy 87%**"""

LogisticModel = LogisticRegression()
LogisticModel.fit(X_train,y_train)

Y_pred_Logistic=LogisticModel.predict(X_test)

logistic_accuracy_score=accuracy_score(y_test,Y_pred_Logistic)

logistic_accuracy_score
# Print test confusion matrix and classification report
print("Test Confusion Matrix")
print(confusion_matrix(y_test, Y_pred_Logistic))
print(classification_report(y_test, Y_pred_Logistic))

# Calculate precision and recall
y_prob = LogisticModel.predict_proba(X_test)
precision, recall, thresholds = precision_recall_curve(y_test, y_prob[:, 1])

# Plot the precision-recall curve
plt.plot(recall, precision, label='logistic model')
plt.legend()
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.show()

"""# **Random Forest Model with Accuracy 88%**"""

Randomforest=RandomForestClassifier()
Randomforest.fit(X_train,y_train)
Y_pred_Randomforest=Randomforest.predict(X_test)

Y_train_pred_Randomforest=Randomforest.predict(X_train)

acc_Randomforest = accuracy_score(Y_pred_Randomforest, y_test)
print(accuracy_score(y_test,Y_pred_Randomforest))

print(confusion_matrix(y_test,Y_pred_Randomforest))
print(classification_report(y_test,Y_pred_Randomforest))


y_prob = Randomforest.predict_proba(X_test)

precision, recall, thresholds = precision_recall_curve(y_test, y_prob[:,1])

plt.plot(recall, precision, label='Random forest')

plt.legend()
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.show()

"""# **Naive Bayes Model with Accuracy 77%**"""

from sklearn.naive_bayes import GaussianNB

# Instantiate the model
gnb = GaussianNB()
gnb.fit(X_train, y_train)
gnb_preds = gnb.predict(X_test)
gnb_accuracy_score=accuracy_score(y_test,gnb_preds)
gnb_accuracy_score
y_prob = gnb.predict_proba(X_test)

precision, recall, thresholds = precision_recall_curve(y_test, y_prob[:,1])

plt.plot(recall, precision, label='Naive Bayes Model')

plt.legend()
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.show()
gnb_accuracy_score